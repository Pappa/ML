{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85440396-eeac-4866-8035-3798af1ebfbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_data shape: (937, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os import path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, Conv2DTranspose, Reshape, Lambda, Activation, BatchNormalization, LeakyReLU, Dropout, ZeroPadding2D, UpSampling2D\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "\n",
    "from models.GAN2 import GAN\n",
    "\n",
    "\n",
    "source_path = './images/miro/mono/'\n",
    "X_data = []\n",
    "\n",
    "\n",
    "for count, filename in enumerate(os.listdir(source_path)):\n",
    "    f = os.path.join(source_path, filename)\n",
    "    image = Image.open(f).convert('L').resize((28, 28))\n",
    "    # print(f\"shape: {np.array(image).shape}\")\n",
    "    X_data.append(np.array(image))\n",
    "\n",
    "X_data = np.array(X_data)\n",
    "X_data = X_data.reshape(X_data.shape[0], 28, 28, 1)\n",
    "print('X_data shape:', X_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bedf811-d006-453c-993f-74e2d1967bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f720101f250>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_data[150,:,:,0], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2655c78d-1729-491a-8221-c6f8bd6221af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run params\n",
    "SECTION = 'gan'\n",
    "RUN_ID = '0001'\n",
    "DATA_NAME = 'miro'\n",
    "RUN_FOLDER = 'run/{}/'.format(SECTION)\n",
    "RUN_FOLDER += '_'.join([RUN_ID, DATA_NAME])\n",
    "\n",
    "if not os.path.exists(RUN_FOLDER):\n",
    "    os.mkdir(RUN_FOLDER)\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'viz'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'images'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'weights'))\n",
    "\n",
    "mode =  'build' #'load' #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8874bd4-3648-4bfc-844e-dd3e554f2491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "discriminator_input (InputLa [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 14, 14, 64)        1664      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 7, 7, 64)          102464    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 128)         204928    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 128)         409728    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 720,833\n",
      "Trainable params: 720,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "filters = [64,64,128,128]\n",
    "kernel_size = [5,5,5,5]\n",
    "strides = [2,2,2,1]\n",
    "momentum = None\n",
    "dropout_rate = 0.4\n",
    "\n",
    "weight_init = RandomNormal(mean=0., stddev=0.02)\n",
    "\n",
    "### discriminator\n",
    "discriminator_input = Input(shape=(28,28,1), name='discriminator_input')\n",
    "\n",
    "x = discriminator_input\n",
    "\n",
    "for i in range(4):\n",
    "\n",
    "    x = Conv2D(\n",
    "        filters = filters[i], \n",
    "        kernel_size = kernel_size[i],\n",
    "        strides = strides[i],\n",
    "        padding = 'same',\n",
    "        kernel_initializer = weight_init\n",
    "    )(x)\n",
    "\n",
    "    if momentum and i > 0:\n",
    "        x = BatchNormalization(momentum = momentum)(x)\n",
    "\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    if dropout_rate:\n",
    "        x = Dropout(rate = dropout_rate)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "discriminator_output = Dense(1, activation='sigmoid', kernel_initializer = weight_init)(x)\n",
    "\n",
    "discriminator = Model(discriminator_input, discriminator_output)\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "639733b1-ef23-406b-95a2-87d8497dd8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "generator_input (InputLayer) [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3136)              316736    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 3136)              12544     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 128)       204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 28, 28, 64)        102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 28, 28, 1)         1601      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 844,161\n",
      "Trainable params: 837,377\n",
      "Non-trainable params: 6,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "upsample = [2, 2, 1, 1]\n",
    "filters = [128, 64, 64,1]\n",
    "kernel_size = [5, 5, 5, 5]\n",
    "strides = [1, 1, 1, 1]\n",
    "momentum = 0.9\n",
    "activation = 'relu'\n",
    "dropout_rate = 0.8\n",
    "\n",
    "weight_init = RandomNormal(mean=0., stddev=0.02)\n",
    "\n",
    "\n",
    "\n",
    "### generator\n",
    "\n",
    "generator_input = Input(shape=(100,), name='generator_input')\n",
    "\n",
    "x = generator_input\n",
    "\n",
    "x = Dense(np.prod((7, 7, 64)), kernel_initializer = weight_init)(x)\n",
    "\n",
    "if momentum:\n",
    "    x = BatchNormalization(momentum = momentum)(x)\n",
    "\n",
    "x = Activation('relu')(x)\n",
    "x = Reshape((7, 7, 64))(x)\n",
    "\n",
    "if dropout_rate:\n",
    "    x = Dropout(rate = dropout_rate)(x)\n",
    "\n",
    "for i in range(4):\n",
    "\n",
    "    if upsample[i] == 2:\n",
    "        x = UpSampling2D()(x)\n",
    "        x = Conv2D(\n",
    "            filters = filters[i]\n",
    "            , kernel_size = kernel_size[i]\n",
    "            , padding = 'same'\n",
    "            , kernel_initializer = weight_init\n",
    "        )(x)\n",
    "    else:\n",
    "\n",
    "        x = Conv2DTranspose(\n",
    "            filters = filters[i]\n",
    "            , kernel_size = kernel_size[i]\n",
    "            , padding = 'same'\n",
    "            , strides = strides[i]\n",
    "            , kernel_initializer = weight_init\n",
    "            )(x)\n",
    "\n",
    "    if i < 3:\n",
    "\n",
    "        if momentum:\n",
    "            x = BatchNormalization(momentum = momentum)(x)\n",
    "\n",
    "        x = Activation('relu')(x)\n",
    "    else:\n",
    "        x = Activation('tanh')(x)\n",
    "\n",
    "\n",
    "generator_output = x\n",
    "\n",
    "generator = Model(generator_input, generator_output)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d00d8789-e559-4cc9-8333-96e57300f24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = GAN(input_dim = (28,28,1)\n",
    "        , discriminator = discriminator\n",
    "        , discriminator_learning_rate = 0.0008\n",
    "        , generator = generator\n",
    "        , generator_learning_rate = 0.0004\n",
    "        , optimiser = 'rmsprop'\n",
    "        , z_dim = 100\n",
    "        )\n",
    "\n",
    "# if mode == 'build':\n",
    "#     gan.save(RUN_FOLDER)\n",
    "# else:\n",
    "#     gan.load_weights(os.path.join(RUN_FOLDER, 'weights/weights.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90302084-c248-4761-8ccb-90d02ed65756",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 2000\n",
    "PRINT_EVERY_N_BATCHES = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7bad0b9-ffaf-4359-a252-da9dd405ef5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: (0.986)(R 1.232, F 0.741)] [D acc: (0.266)(0.531, 0.000)] [G loss: 0.578] [G acc: 1.000]\n",
      "50 [D loss: (0.310)(R 0.000, F 0.621)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.776] [G acc: 0.000]\n",
      "100 [D loss: (0.236)(R 0.000, F 0.471)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.994] [G acc: 0.000]\n",
      "150 [D loss: (0.069)(R 0.000, F 0.138)] [D acc: (1.000)(1.000, 1.000)] [G loss: 2.149] [G acc: 0.000]\n",
      "200 [D loss: (0.004)(R 0.000, F 0.008)] [D acc: (1.000)(1.000, 1.000)] [G loss: 4.426] [G acc: 0.000]\n",
      "250 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 6.886] [G acc: 0.000]\n",
      "300 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 14.591] [G acc: 0.000]\n",
      "350 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 14.642] [G acc: 0.000]\n",
      "400 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 18.413] [G acc: 0.000]\n",
      "450 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 20.735] [G acc: 0.000]\n",
      "500 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 21.642] [G acc: 0.000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d57a92492c24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m gan.train(     \n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mX_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m,\u001b[0m \u001b[0mrun_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRUN_FOLDER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/Pappa/ML/models/GAN2.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x_train, batch_size, epochs, run_folder, print_every_n_batches, using_generator)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_discriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musing_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/Pappa/ML/models/GAN2.py\u001b[0m in \u001b[0;36mtrain_generator\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GDL_book/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   1346\u001b[0m                                                     class_weight)\n\u001b[1;32m   1347\u001b[0m       \u001b[0mtrain_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GDL_book/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GDL_book/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GDL_book/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GDL_book/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1659\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \"\"\"\n\u001b[0;32m-> 1661\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1662\u001b[0m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/anaconda3/envs/GDL_book/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/envs/GDL_book/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    591\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    594\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GDL_book/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gan.train(     \n",
    "    X_data\n",
    "    , batch_size = BATCH_SIZE\n",
    "    , epochs = EPOCHS\n",
    "    , run_folder = RUN_FOLDER\n",
    "    , print_every_n_batches = PRINT_EVERY_N_BATCHES\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74a2a03-07df-4fc0-81de-d6346fe77bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot([x[0] for x in gan.d_losses], color='black', linewidth=0.25)\n",
    "\n",
    "plt.plot([x[1] for x in gan.d_losses], color='green', linewidth=0.25)\n",
    "plt.plot([x[2] for x in gan.d_losses], color='red', linewidth=0.25)\n",
    "plt.plot([x[0] for x in gan.g_losses], color='orange', linewidth=0.25)\n",
    "\n",
    "plt.xlabel('batch', fontsize=18)\n",
    "plt.ylabel('loss', fontsize=16)\n",
    "\n",
    "plt.xlim(0, 2000)\n",
    "plt.ylim(0, 2)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ac92f7-628a-4895-8f7f-1b67fd58473b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot([x[3] for x in gan.d_losses], color='black', linewidth=0.25)\n",
    "plt.plot([x[4] for x in gan.d_losses], color='green', linewidth=0.25)\n",
    "plt.plot([x[5] for x in gan.d_losses], color='red', linewidth=0.25)\n",
    "plt.plot([x[1] for x in gan.g_losses], color='orange', linewidth=0.25)\n",
    "\n",
    "plt.xlabel('batch', fontsize=18)\n",
    "plt.ylabel('accuracy', fontsize=16)\n",
    "\n",
    "plt.xlim(0, 2000)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
