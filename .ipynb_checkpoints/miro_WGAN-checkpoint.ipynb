{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WGAN Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "x_train shape: (937, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models.WGAN import WGAN\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "source_path = './images/miro/square/'\n",
    "X_data = []\n",
    "\n",
    "\n",
    "for count, filename in enumerate(os.listdir(source_path)):\n",
    "    f = os.path.join(source_path, filename)\n",
    "    image = Image.open(f).convert('RGB').resize((32, 32))\n",
    "    # print(f\"shape: {np.array(image).shape}\")\n",
    "    X_data.append(np.array(image))\n",
    "\n",
    "x_train = np.array(X_data)\n",
    "print('x_train shape:', x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run params\n",
    "SECTION = 'wgan'\n",
    "RUN_ID = '0002'\n",
    "DATA_NAME = 'miro'\n",
    "RUN_FOLDER = 'run/{}/'.format(SECTION)\n",
    "RUN_FOLDER += '_'.join([RUN_ID, DATA_NAME])\n",
    "\n",
    "if not os.path.exists(RUN_FOLDER):\n",
    "    os.mkdir(RUN_FOLDER)\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'viz'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'images'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'weights'))\n",
    "\n",
    "mode =  'build' #'load' #\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if DATA_NAME == 'cars':\n",
    "#     label = 1\n",
    "# elif DATA_NAME == 'horses':\n",
    "#     label = 7\n",
    "# (x_train, y_train) = load_cifar(label, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa6d9e39520>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[110,:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if mode == 'build':\n",
    "\n",
    "    gan = WGAN(input_dim = (32,32,3)\n",
    "            , critic_conv_filters = [32,64,128,128]\n",
    "            , critic_conv_kernel_size = [5,5,5,5]\n",
    "            , critic_conv_strides = [2,2,2,1]\n",
    "            , critic_batch_norm_momentum = None\n",
    "            , critic_activation = 'leaky_relu'\n",
    "            , critic_dropout_rate = None\n",
    "            , critic_learning_rate = 0.00005\n",
    "            , generator_initial_dense_layer_size = (4, 4, 128)\n",
    "            , generator_upsample = [2,2, 2,1]\n",
    "            , generator_conv_filters = [128,64,32,3]\n",
    "            , generator_conv_kernel_size = [5,5,5,5]\n",
    "            , generator_conv_strides = [1,1, 1,1]\n",
    "            , generator_batch_norm_momentum = 0.8\n",
    "            , generator_activation = 'leaky_relu'\n",
    "            , generator_dropout_rate = None\n",
    "            , generator_learning_rate = 0.00005\n",
    "            , optimiser = 'rmsprop'\n",
    "            , z_dim = 100\n",
    "            )\n",
    "    gan.save(RUN_FOLDER)\n",
    "\n",
    "else:\n",
    "    gan.load_weights(os.path.join(RUN_FOLDER, 'weights/weights.h5'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "critic_input (InputLayer)    [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "critic_conv_0 (Conv2D)       (None, 16, 16, 32)        2432      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_56 (LeakyReLU)   (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "critic_conv_1 (Conv2D)       (None, 8, 8, 64)          51264     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_57 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "critic_conv_2 (Conv2D)       (None, 4, 4, 128)         204928    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_58 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "critic_conv_3 (Conv2D)       (None, 4, 4, 128)         409728    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_59 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 670,401\n",
      "Trainable params: 670,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.critic.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "generator_input (InputLayer) [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 2048)              206848    \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_60 (LeakyReLU)   (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "reshape_7 (Reshape)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_18 (UpSampling (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "generator_conv_0 (Conv2D)    (None, 8, 8, 128)         409728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_61 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_19 (UpSampling (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "generator_conv_1 (Conv2D)    (None, 16, 16, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_62 (LeakyReLU)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_20 (UpSampling (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "generator_conv_2 (Conv2D)    (None, 32, 32, 32)        51232     \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_63 (LeakyReLU)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "generator_conv_3 (Conv2DTran (None, 32, 32, 3)         2403      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 32, 32, 3)         0         \n",
      "=================================================================\n",
      "Total params: 884,163\n",
      "Trainable params: 879,619\n",
      "Non-trainable params: 4,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "EPOCHS = 6000\n",
    "PRINT_EVERY_N_BATCHES = 5\n",
    "N_CRITIC = 5\n",
    "CLIP_THRESHOLD = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "0 [D loss: (-0.107)(R -0.214, F 0.000)]  [G loss: -0.000] \n",
      "5 [D loss: (-103.200)(R -206.742, F 0.342)]  [G loss: -0.767] \n",
      "10 [D loss: (-1371.359)(R -2746.204, F 3.486)]  [G loss: -12.590] \n",
      "15 [D loss: (-6154.637)(R -12347.602, F 38.328)]  [G loss: -61.727] \n",
      "20 [D loss: (-17181.654)(R -34535.113, F 171.806)]  [G loss: -187.236] \n",
      "25 [D loss: (-37314.625)(R -75047.266, F 418.013)]  [G loss: -432.408] \n",
      "30 [D loss: (-72142.273)(R -145129.859, F 845.318)]  [G loss: -842.890] \n",
      "35 [D loss: (-120549.688)(R -242559.531, F 1460.156)]  [G loss: -1450.731] \n",
      "40 [D loss: (-175575.156)(R -353465.656, F 2315.336)]  [G loss: -2282.681] \n",
      "45 [D loss: (-260906.516)(R -525215.750, F 3402.718)]  [G loss: -3344.927] \n",
      "50 [D loss: (-361802.719)(R -728300.875, F 4695.413)]  [G loss: -4618.043] \n",
      "55 [D loss: (-398784.719)(R -802914.375, F 5344.959)]  [G loss: -5185.443] \n",
      "60 [D loss: (-413172.906)(R -831890.750, F 5544.929)]  [G loss: -5382.259] \n",
      "65 [D loss: (-426559.844)(R -858827.875, F 5708.204)]  [G loss: -5536.059] \n",
      "70 [D loss: (-425036.219)(R -855914.500, F 5842.038)]  [G loss: -5663.131] \n",
      "75 [D loss: (-444200.781)(R -894360.375, F 5958.804)]  [G loss: -5769.989] \n",
      "80 [D loss: (-436696.844)(R -879449.875, F 6056.180)]  [G loss: -5860.226] \n",
      "85 [D loss: (-444100.781)(R -894327.750, F 6126.203)]  [G loss: -5939.896] \n",
      "90 [D loss: (-440829.281)(R -887869.875, F 6211.285)]  [G loss: -6011.729] \n",
      "95 [D loss: (-442520.938)(R -891316.812, F 6274.934)]  [G loss: -6076.953] \n",
      "100 [D loss: (-453160.875)(R -912656.375, F 6334.653)]  [G loss: -6132.461] \n",
      "105 [D loss: (-467665.625)(R -941724.875, F 6393.638)]  [G loss: -6182.863] \n",
      "110 [D loss: (-461481.906)(R -929408.625, F 6444.829)]  [G loss: -6231.553] \n",
      "115 [D loss: (-449722.906)(R -905927.250, F 6481.438)]  [G loss: -6276.593] \n",
      "120 [D loss: (-460778.188)(R -928091.250, F 6534.865)]  [G loss: -6319.528] \n",
      "125 [D loss: (-481972.656)(R -970528.000, F 6582.700)]  [G loss: -6358.431] \n",
      "130 [D loss: (-467978.000)(R -942570.625, F 6614.655)]  [G loss: -6394.375] \n",
      "135 [D loss: (-481275.906)(R -969199.750, F 6647.939)]  [G loss: -6425.216] \n",
      "140 [D loss: (-488443.188)(R -983563.750, F 6677.390)]  [G loss: -6452.671] \n",
      "145 [D loss: (-493599.562)(R -993907.688, F 6708.553)]  [G loss: -6476.741] \n",
      "150 [D loss: (-483311.219)(R -973347.438, F 6725.024)]  [G loss: -6498.344] \n",
      "155 [D loss: (-467613.875)(R -941966.375, F 6738.609)]  [G loss: -6516.119] \n",
      "160 [D loss: (-489658.250)(R -986078.750, F 6762.280)]  [G loss: -6532.050] \n",
      "165 [D loss: (-491745.781)(R -990268.500, F 6776.964)]  [G loss: -6546.315] \n",
      "170 [D loss: (-481858.312)(R -970504.000, F 6787.352)]  [G loss: -6559.630] \n",
      "175 [D loss: (-487087.812)(R -980978.062, F 6802.417)]  [G loss: -6571.885] \n",
      "180 [D loss: (-483974.906)(R -974762.750, F 6812.954)]  [G loss: -6583.133] \n",
      "185 [D loss: (-481355.781)(R -969533.312, F 6821.728)]  [G loss: -6593.422] \n",
      "190 [D loss: (-478386.719)(R -963602.750, F 6829.313)]  [G loss: -6603.086] \n",
      "195 [D loss: (-485341.812)(R -977524.062, F 6840.411)]  [G loss: -6610.936] \n",
      "200 [D loss: (-488476.031)(R -983801.750, F 6849.679)]  [G loss: -6618.053] \n",
      "205 [D loss: (-476785.594)(R -960422.625, F 6851.427)]  [G loss: -6624.091] \n",
      "210 [D loss: (-492024.969)(R -990911.375, F 6861.421)]  [G loss: -6629.670] \n",
      "215 [D loss: (-483098.531)(R -973059.688, F 6862.639)]  [G loss: -6633.614] \n",
      "220 [D loss: (-481204.500)(R -969275.375, F 6866.380)]  [G loss: -6636.976] \n",
      "225 [D loss: (-491203.031)(R -989276.750, F 6870.715)]  [G loss: -6638.987] \n",
      "230 [D loss: (-472648.156)(R -952162.562, F 6866.255)]  [G loss: -6640.613] \n",
      "235 [D loss: (-492197.656)(R -991271.500, F 6876.167)]  [G loss: -6642.201] \n",
      "240 [D loss: (-495047.438)(R -996972.438, F 6877.531)]  [G loss: -6642.964] \n",
      "245 [D loss: (-481797.812)(R -970467.125, F 6871.477)]  [G loss: -6643.273] \n",
      "250 [D loss: (-483183.750)(R -973239.750, F 6872.263)]  [G loss: -6643.471] \n",
      "255 [D loss: (-489007.750)(R -984892.375, F 6876.895)]  [G loss: -6643.574] \n",
      "260 [D loss: (-502474.469)(R -1011831.125, F 6882.205)]  [G loss: -6643.614] \n",
      "265 [D loss: (-484859.562)(R -976593.750, F 6874.625)]  [G loss: -6643.581] \n",
      "270 [D loss: (-491250.031)(R -989375.625, F 6875.589)]  [G loss: -6643.507] \n",
      "275 [D loss: (-481776.406)(R -970425.875, F 6873.063)]  [G loss: -6643.410] \n",
      "280 [D loss: (-486375.438)(R -979624.188, F 6873.338)]  [G loss: -6643.263] \n",
      "285 [D loss: (-482820.094)(R -972512.625, F 6872.421)]  [G loss: -6643.144] \n",
      "290 [D loss: (-481630.875)(R -970136.875, F 6875.138)]  [G loss: -6642.967] \n",
      "295 [D loss: (-489337.906)(R -985553.875, F 6878.053)]  [G loss: -6642.777] \n",
      "300 [D loss: (-491736.344)(R -990347.688, F 6874.978)]  [G loss: -6642.573] \n",
      "305 [D loss: (-478196.594)(R -963263.812, F 6870.648)]  [G loss: -6642.332] \n",
      "310 [D loss: (-481684.344)(R -970241.938, F 6873.274)]  [G loss: -6642.099] \n",
      "315 [D loss: (-500967.969)(R -1008815.000, F 6879.077)]  [G loss: -6641.862] \n",
      "320 [D loss: (-488488.969)(R -983852.375, F 6874.465)]  [G loss: -6641.601] \n",
      "325 [D loss: (-496100.000)(R -999076.375, F 6876.406)]  [G loss: -6641.329] \n",
      "330 [D loss: (-491909.875)(R -990694.125, F 6874.352)]  [G loss: -6641.054] \n",
      "335 [D loss: (-476092.469)(R -959052.625, F 6867.694)]  [G loss: -6640.763] \n",
      "340 [D loss: (-484229.688)(R -975329.875, F 6870.524)]  [G loss: -6640.463] \n",
      "345 [D loss: (-500455.500)(R -1007790.250, F 6879.273)]  [G loss: -6640.173] \n",
      "350 [D loss: (-491354.469)(R -989580.688, F 6871.733)]  [G loss: -6639.860] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-c358e4712d04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m gan.train(     \n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m,\u001b[0m \u001b[0mrun_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRUN_FOLDER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/Pappa/ML/models/WGAN.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x_train, batch_size, epochs, run_folder, print_every_n_batches, n_critic, clip_threshold, using_generator)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_critic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m                 \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_critic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musing_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/Pappa/ML/models/WGAN.py\u001b[0m in \u001b[0;36mtrain_critic\u001b[0;34m(self, x_train, batch_size, clip_threshold, using_generator)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0md_loss_real\u001b[0m \u001b[0;34m=\u001b[0m   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0md_loss_fake\u001b[0m \u001b[0;34m=\u001b[0m   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m         \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0md_loss_real\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0md_loss_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GDL_book/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1061\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GDL_book/lib/python3.8/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3629\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3631\u001b[0;31m     fetched = self._callable_fn(*array_vals,\n\u001b[0m\u001b[1;32m   3632\u001b[0m                                 run_metadata=self.run_metadata)\n\u001b[1;32m   3633\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GDL_book/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1468\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1469\u001b[0m         \u001b[0mrun_metadata_ptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_NewBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1470\u001b[0;31m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0m\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1472\u001b[0m                                                run_metadata_ptr)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gan.train(     \n",
    "    x_train\n",
    "    , batch_size = BATCH_SIZE\n",
    "    , epochs = EPOCHS\n",
    "    , run_folder = RUN_FOLDER\n",
    "    , print_every_n_batches = PRINT_EVERY_N_BATCHES\n",
    "    , n_critic = N_CRITIC\n",
    "    , clip_threshold = CLIP_THRESHOLD\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.sample_images(RUN_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot([x[0] for x in gan.d_losses], color='black', linewidth=0.25)\n",
    "\n",
    "plt.plot([x[1] for x in gan.d_losses], color='green', linewidth=0.25)\n",
    "plt.plot([x[2] for x in gan.d_losses], color='red', linewidth=0.25)\n",
    "plt.plot(gan.g_losses, color='orange', linewidth=0.25)\n",
    "\n",
    "plt.xlabel('batch', fontsize=18)\n",
    "plt.ylabel('loss', fontsize=16)\n",
    "\n",
    "# plt.xlim(0, 2000)\n",
    "# plt.ylim(0, 2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_images(img1, img2):\n",
    "    return np.mean(np.abs(img1 - img2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "r, c = 5, 5\n",
    "\n",
    "idx = np.random.randint(0, x_train.shape[0], BATCH_SIZE)\n",
    "true_imgs = (x_train[idx] + 1) *0.5\n",
    "\n",
    "fig, axs = plt.subplots(r, c, figsize=(15,15))\n",
    "cnt = 0\n",
    "\n",
    "for i in range(r):\n",
    "    for j in range(c):\n",
    "        axs[i,j].imshow(true_imgs[cnt], cmap = 'gray_r')\n",
    "        axs[i,j].axis('off')\n",
    "        cnt += 1\n",
    "fig.savefig(os.path.join(RUN_FOLDER, \"images/real.png\"))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, c = 5, 5\n",
    "noise = np.random.normal(0, 1, (r * c, gan.z_dim))\n",
    "gen_imgs = gan.generator.predict(noise)\n",
    "\n",
    "#Rescale images 0 - 1\n",
    "\n",
    "gen_imgs = 0.5 * (gen_imgs + 1)\n",
    "# gen_imgs = np.clip(gen_imgs, 0, 1)\n",
    "\n",
    "fig, axs = plt.subplots(r, c, figsize=(15,15))\n",
    "cnt = 0\n",
    "\n",
    "for i in range(r):\n",
    "    for j in range(c):\n",
    "        axs[i,j].imshow(np.squeeze(gen_imgs[cnt, :,:,:]), cmap = 'gray_r')\n",
    "        axs[i,j].axis('off')\n",
    "        cnt += 1\n",
    "fig.savefig(os.path.join(RUN_FOLDER, \"images/sample.png\"))\n",
    "plt.close()\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(r, c, figsize=(15,15))\n",
    "cnt = 0\n",
    "\n",
    "for i in range(r):\n",
    "    for j in range(c):\n",
    "        c_diff = 99999\n",
    "        c_img = None\n",
    "        for k_idx, k in enumerate((x_train + 1) * 0.5):\n",
    "            \n",
    "            diff = compare_images(gen_imgs[cnt, :,:,:], k)\n",
    "            if diff < c_diff:\n",
    "                c_img = np.copy(k)\n",
    "                c_diff = diff\n",
    "        axs[i,j].imshow(c_img, cmap = 'gray_r')\n",
    "        axs[i,j].axis('off')\n",
    "        cnt += 1\n",
    "\n",
    "fig.savefig(os.path.join(RUN_FOLDER, \"images/sample_closest.png\"))\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
