{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WGAN Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (937, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models.WGAN import WGAN\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "source_path = './images/miro/square/'\n",
    "X_data = []\n",
    "\n",
    "\n",
    "for count, filename in enumerate(os.listdir(source_path)):\n",
    "    f = os.path.join(source_path, filename)\n",
    "    image = Image.open(f).convert('RGB').resize((32, 32))\n",
    "    # print(f\"shape: {np.array(image).shape}\")\n",
    "    X_data.append(np.array(image))\n",
    "\n",
    "x_train = np.array(X_data)\n",
    "print('x_train shape:', x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run params\n",
    "SECTION = 'wgan'\n",
    "RUN_ID = '0002'\n",
    "DATA_NAME = 'miro'\n",
    "RUN_FOLDER = 'run/{}/'.format(SECTION)\n",
    "RUN_FOLDER += '_'.join([RUN_ID, DATA_NAME])\n",
    "\n",
    "if not os.path.exists(RUN_FOLDER):\n",
    "    os.mkdir(RUN_FOLDER)\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'viz'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'images'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'weights'))\n",
    "\n",
    "mode =  'build' #'load' #\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if DATA_NAME == 'cars':\n",
    "#     label = 1\n",
    "# elif DATA_NAME == 'horses':\n",
    "#     label = 7\n",
    "# (x_train, y_train) = load_cifar(label, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe0119bbf70>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[110,:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if mode == 'build':\n",
    "\n",
    "    gan = WGAN(input_dim = (32,32,3)\n",
    "            , critic_conv_filters = [32,64,128,128]\n",
    "            , critic_conv_kernel_size = [5,5,5,5]\n",
    "            , critic_conv_strides = [2,2,2,1]\n",
    "            , critic_batch_norm_momentum = None\n",
    "            , critic_activation = 'leaky_relu'\n",
    "            , critic_dropout_rate = None\n",
    "            , critic_learning_rate = 0.00005\n",
    "            , generator_initial_dense_layer_size = (4, 4, 128)\n",
    "            , generator_upsample = [2,2, 2,1]\n",
    "            , generator_conv_filters = [128,64,32,3]\n",
    "            , generator_conv_kernel_size = [5,5,5,5]\n",
    "            , generator_conv_strides = [1,1, 1,1]\n",
    "            , generator_batch_norm_momentum = 0.8\n",
    "            , generator_activation = 'leaky_relu'\n",
    "            , generator_dropout_rate = None\n",
    "            , generator_learning_rate = 0.00005\n",
    "            , optimiser = 'rmsprop'\n",
    "            , z_dim = 100\n",
    "            )\n",
    "    gan.save(RUN_FOLDER)\n",
    "\n",
    "else:\n",
    "    gan.load_weights(os.path.join(RUN_FOLDER, 'weights/weights.h5'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "critic_input (InputLayer)    [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "critic_conv_0 (Conv2D)       (None, 16, 16, 32)        2432      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "critic_conv_1 (Conv2D)       (None, 8, 8, 64)          51264     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "critic_conv_2 (Conv2D)       (None, 4, 4, 128)         204928    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "critic_conv_3 (Conv2D)       (None, 4, 4, 128)         409728    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 670,401\n",
      "Trainable params: 670,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.critic.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "generator_input (InputLayer) [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2048)              206848    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "generator_conv_0 (Conv2D)    (None, 8, 8, 128)         409728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "generator_conv_1 (Conv2D)    (None, 16, 16, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "generator_conv_2 (Conv2D)    (None, 32, 32, 32)        51232     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "generator_conv_3 (Conv2DTran (None, 32, 32, 3)         2403      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32, 32, 3)         0         \n",
      "=================================================================\n",
      "Total params: 884,163\n",
      "Trainable params: 879,619\n",
      "Non-trainable params: 4,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "EPOCHS = 6000\n",
    "PRINT_EVERY_N_BATCHES = 5\n",
    "N_CRITIC = 5\n",
    "CLIP_THRESHOLD = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: (-0.132)(R -0.264, F 0.000)]  [G loss: -0.000] \n",
      "5 [D loss: (-110.749)(R -221.533, F 0.035)]  [G loss: -0.634] \n",
      "10 [D loss: (-1590.665)(R -3181.646, F 0.316)]  [G loss: -12.346] \n",
      "15 [D loss: (-7040.700)(R -14108.488, F 27.088)]  [G loss: -63.673] \n",
      "20 [D loss: (-19277.249)(R -38712.414, F 157.917)]  [G loss: -197.833] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c358e4712d04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m gan.train(     \n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m,\u001b[0m \u001b[0mrun_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRUN_FOLDER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/Pappa/ML/models/WGAN.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x_train, batch_size, epochs, run_folder, print_every_n_batches, n_critic, clip_threshold, using_generator)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_critic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m                 \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_critic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musing_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/Pappa/ML/models/WGAN.py\u001b[0m in \u001b[0;36mtrain_critic\u001b[0;34m(self, x_train, batch_size, clip_threshold, using_generator)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mgen_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0md_loss_real\u001b[0m \u001b[0;34m=\u001b[0m   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GDL_book/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m     87\u001b[0m           method.__name__))\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[0;32m~/anaconda3/envs/GDL_book/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1266\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1268\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m             \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GDL_book/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GDL_book/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    616\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/anaconda3/envs/GDL_book/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GDL_book/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1659\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \"\"\"\n\u001b[0;32m-> 1661\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1662\u001b[0m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/anaconda3/envs/GDL_book/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/envs/GDL_book/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    591\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    594\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GDL_book/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gan.train(     \n",
    "    x_train\n",
    "    , batch_size = BATCH_SIZE\n",
    "    , epochs = EPOCHS\n",
    "    , run_folder = RUN_FOLDER\n",
    "    , print_every_n_batches = PRINT_EVERY_N_BATCHES\n",
    "    , n_critic = N_CRITIC\n",
    "    , clip_threshold = CLIP_THRESHOLD\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.sample_images(RUN_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot([x[0] for x in gan.d_losses], color='black', linewidth=0.25)\n",
    "\n",
    "plt.plot([x[1] for x in gan.d_losses], color='green', linewidth=0.25)\n",
    "plt.plot([x[2] for x in gan.d_losses], color='red', linewidth=0.25)\n",
    "plt.plot(gan.g_losses, color='orange', linewidth=0.25)\n",
    "\n",
    "plt.xlabel('batch', fontsize=18)\n",
    "plt.ylabel('loss', fontsize=16)\n",
    "\n",
    "# plt.xlim(0, 2000)\n",
    "# plt.ylim(0, 2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_images(img1, img2):\n",
    "    return np.mean(np.abs(img1 - img2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "r, c = 5, 5\n",
    "\n",
    "idx = np.random.randint(0, x_train.shape[0], BATCH_SIZE)\n",
    "true_imgs = (x_train[idx] + 1) *0.5\n",
    "\n",
    "fig, axs = plt.subplots(r, c, figsize=(15,15))\n",
    "cnt = 0\n",
    "\n",
    "for i in range(r):\n",
    "    for j in range(c):\n",
    "        axs[i,j].imshow(true_imgs[cnt], cmap = 'gray_r')\n",
    "        axs[i,j].axis('off')\n",
    "        cnt += 1\n",
    "fig.savefig(os.path.join(RUN_FOLDER, \"images/real.png\"))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, c = 5, 5\n",
    "noise = np.random.normal(0, 1, (r * c, gan.z_dim))\n",
    "gen_imgs = gan.generator.predict(noise)\n",
    "\n",
    "#Rescale images 0 - 1\n",
    "\n",
    "gen_imgs = 0.5 * (gen_imgs + 1)\n",
    "# gen_imgs = np.clip(gen_imgs, 0, 1)\n",
    "\n",
    "fig, axs = plt.subplots(r, c, figsize=(15,15))\n",
    "cnt = 0\n",
    "\n",
    "for i in range(r):\n",
    "    for j in range(c):\n",
    "        axs[i,j].imshow(np.squeeze(gen_imgs[cnt, :,:,:]), cmap = 'gray_r')\n",
    "        axs[i,j].axis('off')\n",
    "        cnt += 1\n",
    "fig.savefig(os.path.join(RUN_FOLDER, \"images/sample.png\"))\n",
    "plt.close()\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(r, c, figsize=(15,15))\n",
    "cnt = 0\n",
    "\n",
    "for i in range(r):\n",
    "    for j in range(c):\n",
    "        c_diff = 99999\n",
    "        c_img = None\n",
    "        for k_idx, k in enumerate((x_train + 1) * 0.5):\n",
    "            \n",
    "            diff = compare_images(gen_imgs[cnt, :,:,:], k)\n",
    "            if diff < c_diff:\n",
    "                c_img = np.copy(k)\n",
    "                c_diff = diff\n",
    "        axs[i,j].imshow(c_img, cmap = 'gray_r')\n",
    "        axs[i,j].axis('off')\n",
    "        cnt += 1\n",
    "\n",
    "fig.savefig(os.path.join(RUN_FOLDER, \"images/sample_closest.png\"))\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
